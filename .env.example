# LLM Configuration
LLM_API_KEY=your_api_key_here
LLM_BASE_URL=https://api.openai.com/v1
LLM_MODEL=gpt-3.5-turbo

# Database Configuration
DATABASE_PATH=sakila.db

# Application Configuration
HOST=0.0.0.0
PORT=8001
DEBUG=True
FASTAPI_URL=http://localhost:8001/ask

# Vector Store Configuration
VECTOR_STORE_PATH=retriever/faiss_index
EMBEDDING_MODEL=all-MiniLM-L6-v2
TOP_K_RETRIEVAL=5

# LLM Parameters
MAX_TOKENS=500
TEMPERATURE=0.1
LOG_LEVEL=INFO

# Optional: If using different LLM providers
# For OpenAI
# LLM_BASE_URL=https://api.openai.com/v1
# LLM_MODEL=gpt-3.5-turbo

# For Azure OpenAI
# LLM_BASE_URL=https://your-resource.openai.azure.com/openai/deployments/your-deployment
# LLM_MODEL=gpt-35-turbo

# For local LLM (like Ollama)
# LLM_BASE_URL=http://localhost:11434/v1
# LLM_MODEL=llama2

# For Anthropic Claude
# LLM_BASE_URL=https://api.anthropic.com/v1
# LLM_MODEL=claude-3-sonnet-20240229
